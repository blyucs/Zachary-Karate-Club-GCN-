{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[0., 1., 1., 1.],\n        [0., 0., 1., 1.],\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.]], dtype=float32)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_matrix = np.matrix('0,1,1,1;0,0,1,1;1,0,0,0;0,0,1,0',dtype=np.float32)\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[ 0.,  1., -1.,  0.],\n        [ 5.,  3.,  2.,  1.],\n        [ 1.,  0.,  0.,  0.],\n        [ 1.,  1.,  0.,  0.]], dtype=float32)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = np.matrix('0,1,-1,0;5,3,2,1;1,0,0,0;1,1,0,0',dtype = np.float32)\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[ 7.,  4.,  2.,  1.],\n        [ 2.,  1.,  0.,  0.],\n        [ 0.,  1., -1.,  0.],\n        [ 1.,  0.,  0.,  0.]], dtype=float32)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0  = np.dot(adjacency_matrix,feature_matrix)\n",
    "layer_0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[1., 1., 1., 1.],\n        [0., 1., 1., 1.],\n        [1., 0., 1., 0.],\n        [0., 0., 1., 1.]], dtype=float32)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity = np.identity(adjacency_matrix.shape[0])\n",
    "adjacency_matrix += identity\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([4., 3., 2., 2.], dtype=float32)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array(np.sum(adjacency_matrix,axis = 1)).T[0]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4., 0., 0., 0.],\n       [0., 3., 0., 0.],\n       [0., 0., 2., 0.],\n       [0., 0., 0., 2.]], dtype=float32)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagonal_mat = np.diag(d)\n",
    "diagonal_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.5       , 0.        , 0.        , 0.        ],\n       [0.        , 0.57735026, 0.        , 0.        ],\n       [0.        , 0.        , 0.70710677, 0.        ],\n       [0.        , 0.        , 0.        , 0.70710677]], dtype=float32)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inversed_diagonal_mat = np.linalg.inv(diagonal_mat)\n",
    "inversed_diagonal_mat_half_symm = np.linalg.inv(diagonal_mat**0.5)\n",
    "inversed_diagonal_mat_half_symm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_adj_mat_half_symm\n",
      "[[0.5        0.5        0.5        0.5       ]\n",
      " [0.         0.57735026 0.57735026 0.57735026]\n",
      " [0.70710677 0.         0.70710677 0.        ]\n",
      " [0.         0.         0.70710677 0.70710677]]\n",
      "normalized_adj_mat_full_sym\n",
      "[[0.25       0.28867513 0.35355338 0.35355338]\n",
      " [0.         0.3333333  0.40824828 0.40824828]\n",
      " [0.35355338 0.         0.49999997 0.        ]\n",
      " [0.         0.         0.49999997 0.49999997]]\n"
     ]
    }
   ],
   "source": [
    "normalized_adj_mat = np.dot(inversed_diagonal_mat,adjacency_matrix)\n",
    "normalized_adj_mat_half_symm = np.dot(inversed_diagonal_mat_half_symm,adjacency_matrix)\n",
    "print(\"normalized_adj_mat_half_symm\")\n",
    "print(normalized_adj_mat_half_symm)\n",
    "print(\"normalized_adj_mat_full_sym\")\n",
    "normalized_adj_mat_full_symm = inversed_diagonal_mat_half_symm*adjacency_matrix*inversed_diagonal_mat_half_symm\n",
    "print(normalized_adj_mat_full_symm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining relu function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(a):\n",
    "    mask = a > 0\n",
    "    return np.multiply(a,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.25      , 0.        , 0.        , 0.        ],\n       [0.        , 0.33333334, 0.        , 0.        ],\n       [0.        , 0.        , 0.5       , 0.        ],\n       [0.        , 0.        , 0.        , 0.5       ]], dtype=float32)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(inversed_diagonal_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[0, 4, 2, 0],\n        [0, 3, 0, 1]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(np.matrix('-1,4,2,-1;-22,3,-1,1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from networkx import read_edgelist, set_node_attributes, to_numpy_matrix\n",
    "from pandas import read_csv, Series\n",
    "from numpy import array\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet = namedtuple(\n",
    "    'DataSet',\n",
    "    field_names=['X_train', 'y_train', 'X_test', 'y_test', 'network']\n",
    ")\n",
    "\n",
    "def load_karate_club():\n",
    "    network = read_edgelist(\n",
    "        'karate.edgelist',\n",
    "        nodetype=int)\n",
    "\n",
    "    attributes = read_csv(\n",
    "        'karate.attributes.csv',\n",
    "        index_col=['node'])\n",
    "\n",
    "    for attribute in attributes.columns.values:\n",
    "        set_node_attributes(\n",
    "            network,\n",
    "            values=Series(\n",
    "                attributes[attribute],\n",
    "                index=attributes.index).to_dict(),\n",
    "            name=attribute\n",
    "        )\n",
    "  \n",
    "    X_train,y_train = map(array, zip(*[\n",
    "        ([node], data['role'] == 'Administrator')\n",
    "        for node, data in network.nodes(data=True)\n",
    "        if data['role'] in {'Administrator', 'Instructor'}\n",
    "    ]))\n",
    "  \n",
    "    X_test, y_test = map(array, zip(*[\n",
    "        ([node], data['community'] == 'Administrator')\n",
    "        for node, data in network.nodes(data=True)\n",
    "        if data['role'] == 'Member'\n",
    "    ]))\n",
    " \n",
    "    return DataSet(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.bool_. The only supported types are: double, float, float16, int64, int32, and uint8.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-227bab8c2568>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mX_train_flattened\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzkc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mX_test_flattened\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzkc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0my_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzkc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert np.ndarray of type numpy.bool_. The only supported types are: double, float, float16, int64, int32, and uint8."
     ]
    }
   ],
   "source": [
    "zkc = load_karate_club()\n",
    "X_train_flattened = torch.flatten(torch.from_numpy(zkc.X_train))\n",
    "X_test_flattened = torch.flatten(torch.from_numpy(zkc.X_test))\n",
    "y_train = torch.from_numpy(zkc.y_train).to(torch.float)\n",
    "\n",
    "print(y_train)\n",
    "A = to_numpy_matrix(zkc.network)\n",
    "A = torch.from_numpy(np.array(A))\n",
    "print(A)\n",
    "print(X_train_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpectralRule and LogisticRegressor Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralRule(nn.Module):\n",
    "    \n",
    "    def __init__(self,A,input_units,output_units,activation = 'tanh'):\n",
    "        \n",
    "        super(SpectralRule,self).__init__()\n",
    "        \n",
    "        self.input_units = input_units\n",
    "        self.output_units = output_units\n",
    "        self.linear_layer = nn.Linear(self.input_units,self.output_units)\n",
    "        nn.init.xavier_normal_(self.linear_layer.weight)\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        else:\n",
    "            self.activation = nn.Identity()\n",
    "        #Created Identity Matrix\n",
    "        I = torch.eye(A.shape[1])\n",
    "       \n",
    "        #Adding self loops to the adjacency matrix\n",
    "        A_hat = A + I\n",
    "        A_hat = A_hat.to(torch.double)\n",
    "       \n",
    "        #Inverse degree Matrix\n",
    "        D = torch.diag(torch.pow(torch.sum(A_hat,dim = 0),-0.5),0)\n",
    "       \n",
    "        #applying spectral rule\n",
    "        self.A_hat = torch.matmul(torch.matmul(D,A_hat),D)\n",
    "        self.A_hat.requires_grad = False\n",
    "       \n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        #aggregation\n",
    "        aggregation = torch.matmul(self.A_hat,X)\n",
    "         \n",
    "        #propagation\n",
    "        linear_output = self.linear_layer(aggregation.to(torch.float))\n",
    "      \n",
    "        propagation = self.activation(linear_output)\n",
    "          \n",
    "        return propagation.to(torch.double)\n",
    "\n",
    "class LogisticRegressor(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_units,output_units):\n",
    "        super(LogisticRegressor,self).__init__()\n",
    "        \n",
    "        self.Linear = nn.Linear(input_units,output_units,bias=True)\n",
    "        nn.init.xavier_normal_(self.Linear.weight)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,X):\n",
    "        linear_output = self.Linear(X.to(torch.float))\n",
    "        return self.sigmoid(linear_output)\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = torch.eye(A.shape[1])\n",
    "identity = identity.to(torch.double)\n",
    "identity.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_config = [(4,'tanh'),(2,'tanh')]\n",
    "\n",
    "class FeatureModel(nn.Module):\n",
    "    def __init__(self,A,hidden_layer_config,initial_input_size):\n",
    "        super(FeatureModel,self).__init__()\n",
    "        \n",
    "        self.hidden_layer_config = hidden_layer_config\n",
    "        \n",
    "        self.moduleList = list()\n",
    "        \n",
    "        self.initial_input_size = initial_input_size\n",
    "        \n",
    "        for input_size,activation in hidden_layer_config:\n",
    "            \n",
    "            self.moduleList.append(SpectralRule(A,self.initial_input_size,input_size,activation))\n",
    "            self.initial_input_size = input_size\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.sequentialModule = nn.Sequential(*self.moduleList)\n",
    "      \n",
    "           \n",
    "    def forward(self,X):\n",
    "        output = self.sequentialModule(X)\n",
    "       \n",
    "        return output\n",
    "\n",
    "class ClassifierModel(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(ClassifierModel,self).__init__()\n",
    "        self.logisticRegressor = LogisticRegressor(input_units=input_size,output_units= output_size)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        classified  = self.logisticRegressor(X)\n",
    "        return classified\n",
    "    \n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self,A,hidden_layer_config,initial_input_size):\n",
    "        super(HybridModel,self).__init__()\n",
    "        self.featureModel = FeatureModel(A,hidden_layer_config,identity.shape[1])\n",
    "        self.featureModelOutputSize = self.featureModel.initial_input_size\n",
    "        self.classifier = ClassifierModel(self.featureModelOutputSize,1)\n",
    "        self.featureModelOutput = None\n",
    "    \n",
    "    def forward(self,X):\n",
    "        \n",
    "        outputFeature = self.featureModel(X)\n",
    "        classified = self.classifier(outputFeature)\n",
    "        self.featureModelOutput = outputFeature\n",
    "        return classified\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Matrix as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridModel(A,hidden_layer_config,identity.shape[1])\n",
    "\n",
    "output = model(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zkc.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.01,momentum=0.9)\n",
    "featureoutput = None\n",
    "\n",
    "def train(model , epoch , criterion , optimizer , feature):\n",
    "    cumLoss = 0\n",
    "    losses = list()\n",
    "    \n",
    "    for j in range(epoch): \n",
    "        two_loss = 0\n",
    "        for i,node in enumerate(X_train_flattened):\n",
    "           \n",
    "            output = model(feature)[node]\n",
    "            \n",
    "            ground_truth = torch.reshape(y_train[i],output.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad() \n",
    "            \n",
    "            loss = criterion(output,ground_truth)\n",
    "            #\\print(\"loss: \",loss.data)\n",
    "            two_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "        losses.append(two_loss)\n",
    "        cumLoss += two_loss\n",
    "    print('avg loss: ',cumLoss/epoch)\n",
    "    torch.save(model.state_dict(),\"./gcn.pth\")\n",
    "    plt.plot(losses)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(model,10000,criterion,optimizer,identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after = None\n",
    "def test(features):\n",
    "    \n",
    "    model = HybridModel(A,hidden_layer_config,identity.shape[1])\n",
    "    model.load_state_dict(torch.load(\"./gcn.pth\"))\n",
    "    model.eval()\n",
    "    correct = 0 \n",
    "    masked_output = list()\n",
    "    for i ,node in enumerate(X_test_flattened):\n",
    "        output = model(features)[node]\n",
    "        masked_output.append(output.ge(0.5))\n",
    "    \n",
    "    return masked_output  \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masked = test(identity)\n",
    "masked = [i.item() for i in masked]\n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gt = torch.from_numpy(zkc.y_test)\n",
    "test_gt = [ i.item() for i in test_gt]\n",
    "test_gt\n",
    "counter = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "\n",
    "correct = zip(masked,test_gt)\n",
    "for (masked,gt) in list(correct):\n",
    "    if masked == gt and masked == True:\n",
    "        tp += 1\n",
    "    if masked == gt and masked == False:\n",
    "        tn += 1\n",
    "    if masked == False and gt == True:\n",
    "        fn += 1\n",
    "    if masked == True and gt == False:\n",
    "        fp += 1\n",
    "accuracy = (tp + tn) / (tp+fp+fn+tn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "print('accuracy ',accuracy)\n",
    "print('precision ',precision)\n",
    "print('recall ',recall)\n",
    "print('F1-score', 2*precision*recall/precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "py3_7",
   "language": "python",
   "display_name": "py3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}